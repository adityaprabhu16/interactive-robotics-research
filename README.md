NOTE: Because this project is done within the University of Minnesota github group, the code and ROS workspace I developed is owned by the laboratory and not something I can share. However! This repository includes both the paper publication, pool trial, as well as various visuals of testing and hooking up this new feature on the robot that would give great context on the content of the paper!

# InteractiveRoboticsResearch
My Fall 2022 Undergraduate Research Opportunities Project in the Interactive Robotics and Vision Laboratory. I developed a new LED gaze cue display to help divers communicate with the robot in a visual light based manner. The LEDs are Adafruit neopixels daisy chained together, and driven by light activation arrays from the raspberry pi.

# Link to Co-Author Publications:
https://www.researchgate.net/publication/372124177_HREyes_Design_Development_and_Evaluation_of_a_Novel_Method_for_AUVs_to_Communicate_Information_and_Gaze_Direction
